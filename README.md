<!-- UPDATED: Nov 21, 2025 -->

# ğŸ“Š Job Market Radar

### **Real-Time Job Market Analytics Pipeline + Skill Extraction + Dashboard**

This project builds a full **end-to-end ETL + analytics system** that collects real job postings from a live API, extracts skills, stores structured results in a database, and visualizes insights through a Streamlit dashboard.

It demonstrates practical data engineering + data analytics skills used in real-world jobs.



# ğŸš€ Features

### âœ“ **Real-time job ingestion**

* Fetches job postings from the **Arbeitnow Job Board API**
* Flexible keyword matching using `.env` (e.g., `data`, `analyst`, `analytics`)
* No API key required

### âœ“ **Database storage**

Supports:

* **SQLite** (default â€” zero setup)
* **PostgreSQL** (production mode)

Tables created:

* `raw_jobs`
* `job_skills`

### âœ“ **Skill extraction (NLP-lite)**

Extracts skills from job descriptions using:

* Keyword matching
* Custom skill dictionary
* Multi-label extraction

### âœ“ **Interactive analytics dashboard**

Built using **Streamlit**:

* Top skills bar chart
* Latest job postings
* Auto-refresh capability

---

# ğŸ—ï¸ Architecture

```
             +-----------------------+
             |    Arbeitnow API      |
             +-----------+-----------+
                         |
                         v
               +------------------+
               |  Ingest Jobs     |
               +------------------+
                         |
                         v
               +------------------+
               |   Pipeline.py    |
               | - clean data     |
               | - extract skills |
               | - store in DB    |
               +------------------+
                         |
                         v
        +---------------------------------+
        |   SQLite / PostgreSQL Database  |
        | raw_jobs       job_skills       |
        +---------------------------------+
                         |
                         v
              +-------------------------+
              |     Streamlit App       |
              +-------------------------+
```



# ğŸ› ï¸ Setup Instructions (Step-by-Step)

## **1. Clone the project**

```bash
git clone https://github.com/Pravya425/job-market-radar.git
cd job-market-radar
```

## **2. Install dependencies**

```bash
pip3 install -r requirements.txt
```

## **3. Create `.env` file**

```
QUERY=data
DB_URL=sqlite:///jobs.db
```

For PostgreSQL:

```
DB_URL=postgresql://postgres:password@localhost:5432/jobs
```

## **4. Run the pipeline**

```bash
python3 src/pipeline.py
```

## **5. Launch the dashboard**

```bash
streamlit run dashboard/app.py
```



# ğŸ¯ Example Screenshots

### **Top Skills Dashboard**

![Top Skills](screenshots/top_skills.png)

### **Latest Job Postings**

![Latest Jobs](screenshots/latest_jobs.png)



# ğŸ“Œ Sample Data (Preview)

A sample of the ingested job postings is stored here:

ğŸ“„ **`data/sample_jobs.csv`**

Example (first rows):

| Title              | Company     | Location  | Created    | Skills                    |
| ------------------ | ----------- | --------- | ---------- | ------------------------- |
| Investment Analyst | ABC Capital | Germany   | 2025-11-20 | Python, Finance, Excel    |
| Technical Writer   | XYZ GmbH    | Nuremberg | 2025-11-19 | Documentation, Confluence |
| Linux System Admin | Telekom AG  | Berlin    | 2025-11-19 | Linux, Networking         |

*(Actual values depend on API results.)*


# ğŸ“ Project Structure

```
job-market-radar/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingest_jobs.py
â”‚   â”œâ”€â”€ extract_skills.py
â”‚   â”œâ”€â”€ load_db.py
â”‚   â”œâ”€â”€ pipeline.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ skills_dict.json
â”‚   â””â”€â”€ sample_jobs.csv
â”‚
â”œâ”€â”€ screenshots/
â”‚   â”œâ”€â”€ top_skills.png
â”‚   â””â”€â”€ latest_jobs.png
â”‚
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ schema.sql
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```



# ğŸš€ Future Enhancements

* Add Airflow/Prefect for scheduled ingestion
* Add sentiment analysis or TF-IDF skill clustering
* Add salary prediction model
* Add multiple job sources (Indeed, LinkedIn, RemoteOK)
* Deploy Streamlit on cloud



# ğŸ™‹ Author

**Pranay Reddy Tatiparti (Pravya425)**
Data Analyst | Data Engineer | AI & ML Practitioner


# â­ If this project helped youâ€¦

Leave a â­ on the repo â€” it helps visibility!